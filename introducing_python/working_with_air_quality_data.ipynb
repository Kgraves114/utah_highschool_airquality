{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Weather Data and Air Quality Data\n",
    "\n",
    "In this notebook we are going to learn how to read tabular data (e.g. spreadsheets) with the python package [Pandas](http://pandas.pydata.org/). Pandas is a very useful tool for datascience applications and provides a number of built in functions that makes it much easier for us to write programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to create a variable that will tell our program where the data are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATADIR = os.path.join(os.path.expanduser(\"~\"), \"DATA\", \"TimeSeries\", \"EPA\")\n",
    "os.path.exists(DATADIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What files are in the directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir(DATADIR)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the air quality data\n",
    "\n",
    "We'll use the Pandas ``read_excel`` function to read in our data into a Pandas **dataframe**. Pandas will automatically recongize column names, and data types (e.g. text, numbers). After we read in the data, we'll take a quick look at what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slc = pd.read_excel(os.path.join(DATADIR, 'Salt_Lake_2016_PM25.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe is an object with attributes and methods.\n",
    "\n",
    "Some important attributes are \n",
    "\n",
    "* columns\n",
    "* shape\n",
    "\n",
    "Useful methods include ``head`` and ``tail``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(slc.columns)\n",
    "print(slc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In addition to looking at the column names, we can also look at the data\n",
    "\n",
    "See what happens when you pass an integer number to ``head`` (e.g. ``head(15)``. Try changing ``head`` to ``tail``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is lots of stuff here, more than we're interested in. ``Thow it away``\n",
    "\n",
    "#### What columns do we want to keep?\n",
    "#### What is the difference between ``Time local`` and ``Time GMT``?\n",
    "\n",
    "* Hint: ``GMT`` is more appropriately called ``UTC``\n",
    "\n",
    "### There are lots of ways to throw data away\n",
    "\n",
    "1. We can tell Pandas what columns to read when reading in the data.\n",
    "1. We can tell Pandas to drop particular columns\n",
    "1. We can create a new pandas dataframe by explicitly stating which columns we want to use. (This is the approach we will use.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"A4ZysWTWXEk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc = slc[[\"Date Local\", \"Time Local\", \n",
    "           \"Sample Measurement\", \"MDL\", \n",
    "           \"Latitude\", \"Longitude\", \"Site Num\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "* Dates and times are split into separate columns\n",
    "* We have both local time and UTC time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dates and Time\n",
    "\n",
    "Dates and times are an important data type, and tricky---think leap years, time zones, etc, days of the week, etc. Luckily, Python comes with date and time objects and lots of functions and methods for working with them.  \n",
    "\n",
    "* We'll use the [``datetime`` object ``combine`` method](https://docs.python.org/3/library/datetime.html#datetime.datetime.combine) to merge the date and time columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obs=20\n",
    "print(slc.loc[obs][\"Date Local\"], slc.loc[obs][\"Time Local\"])\n",
    "print(datetime.datetime.combine(slc.loc[obs][\"Date Local\"], \n",
    "                                slc.loc[obs][\"Time Local\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying ``datetime.combine`` to all the dates and times in our dataframe\n",
    "\n",
    "We're going to create a new column called \"Date/Time Local\" using the dataframe method ``apply``. ``apply`` takes a function and applies it to the data in the dataframe. In this case we going to do some fancy Python and create what is called an anonymous function with a ``lambda`` statement. \n",
    "\n",
    "See if you can describe what we are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc[\"Date/Time Local\"] = \\\n",
    "slc.apply(lambda x: datetime.datetime.combine(x[\"Date Local\"],\n",
    "                                              x[\"Time Local\"]), \n",
    "          axis=1)\n",
    "slc[\"Date/Time Local\"].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the data\n",
    "\n",
    "Since we have two different measurement sites, we're going to select only the data for site 3006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc[slc[\"Site Num\"]==3006].plot(x=\"Date Local\", \n",
    "                                y=\"Sample Measurement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slc_weather = pd.read_excel(os.path.join(DATADIR, 'SLC_Weather_2016.xlsx'))\n",
    "slc_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data file uses the 2nd row to describe the **units**. \n",
    "\n",
    "* This is confusing Pandas \n",
    "* Let's skip the second row\n",
    "* This file uses a \"-\" to indicate data are missing. We need to tell Pandas this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc_weather = pd.read_excel(os.path.join(DATADIR, \n",
    "                                         'SLC_Weather_2016.xlsx'), \n",
    "                            skiprows=[1],\n",
    "                           na_values='-')\n",
    "slc_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc_weather['Day'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc_weather.plot(x=\"Day\", y=\"High\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Weather Data Have Resolution of Days\n",
    "## Our pollutant data has resolution of hours\n",
    "## What should we do?\n",
    "\n",
    "### We want to aggregate the data across days. \n",
    "#### How might we do this?\n",
    "\n",
    "1. What was the maximum value?\n",
    "1. What was the minimum value?\n",
    "1. What was the sum of the value?\n",
    "1. What was the average (mean) of the value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc.groupby(\"Date Local\", as_index=False).aggregate(np.mean).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group and take sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc.groupby(\"Date Local\", as_index=False).aggregate(np.sum).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to combine the pollution data with the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc_day_all = slc_day.merge(slc_weather, \n",
    "                            left_on=\"Date Local\", \n",
    "                            right_on=\"Day\")\n",
    "slc_day_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Relationship between various weather variables and ``Sample Measurement``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots(1)\n",
    "slc_day_all[slc_day_all[\"Site Num\"]==3006].plot(x=\"Date Local\", \n",
    "                                                y=\"High\", ax=ax1)\n",
    "slc_day_all[slc_day_all[\"Site Num\"]==3006].plot(secondary_y=True, x=\"Date Local\", \n",
    "                                                y=\"Sample Measurement\", ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">University of Uah Data Science for Health</span> by <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">Brian E. Chapman</span> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
